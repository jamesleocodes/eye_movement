{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File PD104 is started.\n",
      "File PD104 is done.\n",
      "File PD106 is started.\n",
      "File PD106 is done.\n",
      "File PD107 is started.\n",
      "File PD107 is done.\n",
      "File PD108 is started.\n",
      "File PD108 is done.\n",
      "File PD109 is started.\n",
      "File PD109 is done.\n",
      "File PD111 is started.\n",
      "File PD111 is done.\n",
      "File PD112 is started.\n",
      "File PD112 is done.\n",
      "File PD119 is started.\n",
      "File PD119 is done.\n",
      "File PD120 is started.\n",
      "File PD120 is done.\n",
      "File PD121 is started.\n",
      "File PD121 is done.\n",
      "File PD122 is started.\n",
      "File PD122 is done.\n",
      "File PD126 is started.\n",
      "File PD126 is done.\n",
      "File PDPY101 is started.\n",
      "File PDPY101 is done.\n",
      "File PDQE102 is started.\n",
      "File PDQE102 is done.\n",
      "File PDQE103 is started.\n",
      "File PDQE103 is done.\n",
      "File PDQE104 is started.\n",
      "File PDQE104 is done.\n",
      "File PDQE105 is started.\n",
      "File PDQE105 is done.\n",
      "File PDQE107 is started.\n",
      "File PDQE107 is done.\n",
      "File PDQE108 is started.\n",
      "File PDQE108 is done.\n",
      "File PDQE112 is started.\n",
      "File PDQE112 is done.\n",
      "File PDQE113 is started.\n",
      "File PDQE113 is done.\n",
      "File PDQE114 is started.\n",
      "File PDQE114 is done.\n",
      "File PDQE115 is started.\n",
      "File PDQE115 is done.\n",
      "File PDPW104 is started.\n",
      "Columns for subject code PDPW104 not found. Skipping...\n",
      "File PDPW106 is started.\n",
      "File PDPW106 is done.\n",
      "File PDPW107 is started.\n",
      "File PDPW107 is done.\n",
      "File PDPW109 is started.\n",
      "File PDPW109 is done.\n",
      "File PDPW110 is started.\n",
      "File PDPW110 is done.\n",
      "File PDPW111 is started.\n",
      "File PDPW111 is done.\n",
      "File PDPW112 is started.\n",
      "File PDPW112 is done.\n",
      "File PDPW113 is started.\n",
      "File PDPW113 is done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Tuesday 1 May 2023\n",
    "Author: ZAW\n",
    "\"\"\"\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "### Load the subject and stiumuls repect to their speed\n",
    "path = os.getcwd()\n",
    "dirname = os.path.dirname(path)\n",
    "# for HC\n",
    "data_file = 'data/four_degPD.csv'\n",
    "# # for PD\n",
    "#data_file = 'data/PD/one_deg.csv'\n",
    "\n",
    "data_path = os.path.join(dirname,data_file)\n",
    "# data = pd.read_csv(data_path)\n",
    "data= pd.read_csv(data_path)\n",
    "\n",
    "#import CSV data for stimulus\n",
    "path_sti = os.getcwd()\n",
    "dirname_sti = os.path.dirname(path_sti)\n",
    "data_file_sti = 'data/4_degSti.xlsx'\n",
    "data_path_sti = os.path.join(dirname_sti,data_file_sti)\n",
    "rawdata = pd.read_excel(data_path_sti)\n",
    "data_st = np.array(rawdata[1:],dtype=np.float)\n",
    "time = data_st[:,1]\n",
    "position = data_st[:,0]\n",
    "\n",
    "FirstTrialHC = []\n",
    "\n",
    "# List of subject codes (e.g. PD001, PD002, etc.)\n",
    "\n",
    "# subject_codes = [\"PD001\",\"PD002\",\"PD003\",\"PD004\",\"PD005\",\"PD006\",\"PD007\",\"PD008\",\"PD009\",\"PD010\",\n",
    "#  \"PD011\",\"PD012\",\"PD013\",\"PDN015\",\"PDN017\",\"PDN018\",\"PDN019\",\"PDN022\",\"PD026\"]\n",
    "\n",
    "subject_codes = ['PD104','PD106','PD107','PD108','PD109','PD111','PD112','PD119','PD120','PD121',\n",
    " 'PD122','PD126','PDPY101','PDQE102','PDQE103','PDQE104','PDQE105','PDQE107','PDQE108','PDQE112',\n",
    " 'PDQE113','PDQE114','PDQE115','PDPW104','PDPW106','PDPW107','PDPW109','PDPW110','PDPW111','PDPW112',\n",
    " 'PDPW113']\n",
    "\n",
    "#list(set([col[3:] for col in data.columns if col.startswith('x1_')]))\n",
    "\n",
    "for subject_code in subject_codes:\n",
    "    ### Load the subject and stiumuls repect to their speed\n",
    "    path = os.getcwd()\n",
    "    dirname = os.path.dirname(path)\n",
    "    # for HC\n",
    "    data_file = 'data/four_degPD.csv'\n",
    "    # # for PD\n",
    "    #data_file = 'data/PD/one_deg.csv'\n",
    "\n",
    "    data_path = os.path.join(dirname,data_file)\n",
    "    # data = pd.read_csv(data_path)\n",
    "    data= pd.read_csv(data_path)\n",
    "    print('File '+ str(subject_code)+ ' is started.') \n",
    "    x_column = f'x2_{subject_code}'\n",
    "    y_column = f'y2_{subject_code}'\n",
    "\n",
    "    # Check if both columns exist in the DataFrame before accessing them\n",
    "    if x_column in data.columns and y_column in data.columns:\n",
    "        data_hc = data[[x_column, y_column]]\n",
    "    else:\n",
    "        print(f\"Columns for subject code {subject_code} not found. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    y_data = data_hc[x_column]\n",
    "    x_data = data_hc[y_column]\n",
    "\n",
    "    # data_hc = data[['x1_PD001','y1_PD001']] # change the ID each subject code(e.g PD001 or PD003)\n",
    "    # y_data = data_hc[data_hc.columns[0]]\n",
    "    # x_data = data_hc[data_hc.columns[1]]\n",
    "\n",
    "\n",
    "    # Trigonometric Functions\n",
    "    # Trigonometric functions\n",
    "\n",
    "    # Define the function\n",
    "    def func(x, a, b, c):  #Position as a function of time.\n",
    "        return a*(2/np.pi)*np.arcsin(np.sin(np.pi*(b*x+c)))\n",
    "\n",
    "    #initial guesses( This has to change depend on stimulus speed)\n",
    "    #for 1 degree per second: [10, 0.05, 0]\n",
    "    #for 2 degrees per second: [10, 0.1, 0]\n",
    "    #for 4 degrees per second: [10, 0.2, 0]\n",
    "    #for 6 degrees per second: [10, 0.3, 0]\n",
    "    #for 8 degrees per second: [10, 0.4, 0]\n",
    "    InitialGuess = [10, 0.2, 0] # for one degree\n",
    "\n",
    "    # Perform curve fitting\n",
    "    popt, pcov = curve_fit(func,position,time, p0=InitialGuess)\n",
    "\n",
    "    # Extract the optimal values of a, b, and c\n",
    "    a, b, c = popt\n",
    "    # print(\"a =\", a)\n",
    "    # print(\"b =\", b)\n",
    "    # print(\"c =\", c)\n",
    "\n",
    "    # Fit the curve\n",
    "    fit_time = func(y_data,a,b,c)\n",
    "    # plt.plot(y_data,fit_time)\n",
    "    # plt.show()\n",
    "\n",
    "    # Find the residual\n",
    "    # Different(aka residual)\n",
    "    diff = x_data - fit_time\n",
    "\n",
    "    dt_array = np.array(diff)\n",
    "    dt_array = pd.DataFrame(dt_array,columns=['diff'])\n",
    "    window_size = 2\n",
    "    dt_array['Moving_Average'] = dt_array['diff'].rolling(window=window_size).mean()\n",
    "    #plt.plot(y_data,dt_array['Moving_Average'])\n",
    "    # create dataframe\n",
    "    data = {'Time':y_data,'POS':dt_array['Moving_Average']}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # The whole dataset\n",
    "    # Plot specific range\n",
    "    x_start = 2.5\n",
    "    x_end = 22.5\n",
    "\n",
    "    # Filter the data points within the disired range using boolean indexing\n",
    "    mask = (df['Time'] >= x_start) & (df['Time'] <= x_end)\n",
    "    x_data_range = df.loc[mask]\n",
    "\n",
    "    data = {'Time':x_data_range['Time'],'POS':x_data_range['POS']}\n",
    "    df_test = pd.DataFrame(data)\n",
    "\n",
    "    # Determine the integration window\n",
    "    def check_sign(x):\n",
    "        if x > 0:\n",
    "            return \"Positive\"\n",
    "        else:\n",
    "            return \"Negative\"\n",
    "    df_test['Sign'] = df_test['POS'].apply(check_sign)\n",
    "\n",
    "    # Condition window width \n",
    "    def calculate_start_end(row):\n",
    "        global last_positive, last_negative\n",
    "        if row['Sign'] == 'Positive':\n",
    "            if row.name == 0 or df_test.loc[row.name - 1, 'Sign'] != 'Positive':\n",
    "                last_positive = row['Time']\n",
    "                return last_positive, '', '', ''\n",
    "            elif row.name < len(df_test) - 1 and df_test.loc[row.name + 1, 'Sign'] != 'Positive':\n",
    "                pos_end = row['Time']\n",
    "                last_positive = ''\n",
    "                return '', pos_end, '', ''\n",
    "            else:\n",
    "                return '', '', '', ''\n",
    "        elif row['Sign'] == 'Negative':\n",
    "            if row.name == 0 or df_test.loc[row.name - 1, 'Sign'] != 'Negative':\n",
    "                last_negative = row['Time']\n",
    "                return '', '', last_negative, ''\n",
    "            elif row.name < len(df_test) - 1 and df_test.loc[row.name + 1, 'Sign'] != 'Negative':\n",
    "                last_negative = row['Time']\n",
    "                return '', '', '', last_negative\n",
    "            else:\n",
    "                return '', '', '', ''\n",
    "        else:\n",
    "            return '', '', '', ''\n",
    "\n",
    "    # Initialize the last positive and negative values to empty strings \n",
    "    last_positive = ''\n",
    "    last_negative = ''\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    # Apply the custom function to create new columns\n",
    "    df_test['PosTim_Start'], df_test['PosTim_End'], df_test['NegTim_Start'], df_test['NegTim_End'] = zip(*df_test.apply(calculate_start_end, axis=1))\n",
    "\n",
    "    # Fill the empty cells with an empty string\n",
    "    df_test['PosTim_Start'] = df_test['PosTim_Start'].fillna('') \n",
    "    df_test['PosTim_End'] = df_test['PosTim_End'].fillna('')\n",
    "    df_test['NegTim_Start'] = df_test['NegTim_Start'].fillna('')\n",
    "    df_test['NegTim_End'] = df_test['NegTim_End'].fillna('')\n",
    "\n",
    "    # Print the resulting dataframe \n",
    "    #print(df_test)\n",
    "\n",
    "\n",
    "    # Positive time start trimming\n",
    "    # Select the non-empty values in the 'Pos_Start' column\n",
    "    pos_start_values = df_test.loc[df_test['PosTim_Start'] != '', 'PosTim_Start'].values\n",
    "\n",
    "    # Round the values in the 'Pos_Start' column to two decimal places\n",
    "    # rounded_pos_start_values = []\n",
    "    # for value in pos_start_values:\n",
    "    #     rounded_pos_start_values.append(round(value - 0.003, 2))\n",
    "\n",
    "    # Convert the list of rounded values back to a NumPy array\n",
    "    postim_start_values = np.array(pos_start_values)\n",
    "\n",
    "    # Print the non-empty values\n",
    "    #print(postim_start_values)\n",
    "\n",
    "\n",
    "    # Positive time end triming\n",
    "    # Select the non-empty values in the 'Pos_End' column\n",
    "    pos_end_values = df_test.loc[df_test['PosTim_End'] != '', 'PosTim_End'].values\n",
    "\n",
    "    # Round the values in the 'Pos_End' column to two decimal places\n",
    "    # rounded_pos_end_values = []\n",
    "    # for value in pos_end_values:\n",
    "    #     rounded_pos_end_values.append(round(value - 0.02, 2))\n",
    "\n",
    "    # Convert the list of rounded values back to a NumPy array\n",
    "    postim_end_values = np.array(pos_end_values)\n",
    "\n",
    "    # Print the non-empty values\n",
    "    #print(postim_end_values)\n",
    "\n",
    "\n",
    "    # Reload the raw data for mapping\n",
    "    data = data_hc.rename(columns={data_hc.columns.values[0]:\"Position\",\n",
    "                                data_hc.columns.values[1]:'Time'})\n",
    "\n",
    "\n",
    "    # Map the start positive time to POS in raw data\n",
    "    # Create a dictionary from the mapping list\n",
    "    mapping_list = postim_start_values\n",
    "\n",
    "    # Map the values to the 'POS' column in raw\n",
    "    mapped_posSt = data.loc[data['Position'].isin(mapping_list),'Time']\n",
    "\n",
    "\n",
    "    # Map the end positive time to POS in raw data\n",
    "    # Create a dictionary from the mapping list\n",
    "    mapping_list = postim_end_values\n",
    "\n",
    "    # Map the values to the 'POS' column in raw\n",
    "    mapped_posEnd = data.loc[data['Position'].isin(mapping_list),'Time']\n",
    "\n",
    "\n",
    "    # Velocity param positive dataframe\n",
    "    # # column miss match\n",
    "    # Check lengths and truncate longer column \n",
    "    if len(postim_start_values) > len(mapped_posSt): \n",
    "        postim_start_values = postim_start_values[:len(mapped_posSt)] \n",
    "    elif len(mapped_posSt) > len(postim_start_values):\n",
    "        mapped_posSt = mapped_posSt[:len(postim_start_values)]      \n",
    "\n",
    "    # Now columns have equal length \n",
    "    data_param = {'positive_x1':postim_start_values,'positive_y1':mapped_posSt}             \n",
    "    param_vel_start = pd.DataFrame(data_param)\n",
    "\n",
    "    data_param= {'positive_x2':postim_end_values,'positive_y2':mapped_posEnd}\n",
    "    param_vel_end = pd.DataFrame(data_param)\n",
    "\n",
    "    # Reset the indices of the DataFrames\n",
    "    param_vel_start = param_vel_start.reset_index(drop=True)\n",
    "    param_vel_end = param_vel_end.reset_index(drop=True)\n",
    "\n",
    "    # Concatenate the DataFrames horizontally\n",
    "    param_vel_positive_final = pd.concat([param_vel_start,param_vel_end],axis=1)\n",
    "    #param_vel_positive_final['Del_X'] = param_vel_positive_final['positive_x2'] - param_vel_positive_final['positive_x1']\n",
    "\n",
    "    param_vel_positive_final['Del_X'] = (param_vel_positive_final['positive_x2'] - \n",
    "                                        param_vel_positive_final['positive_x1']).where(~param_vel_positive_final['positive_x2'].isnull(), np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # # Remove short duration SWJ from 50 ms to 400 ms\n",
    "    param_vel_positive_final = param_vel_positive_final[(param_vel_positive_final['Del_X'] > 0.4) & \n",
    "                                                        (param_vel_positive_final['Del_X'] < 2.00)]\n",
    "\n",
    "\n",
    "    # iterate over the rows of the dataframe\n",
    "    prev_positive_x2 = None\n",
    "    for i, row in param_vel_positive_final.iterrows():\n",
    "        # check if this is not the first row\n",
    "        if prev_positive_x2 is not None:\n",
    "            # check if positive_x1 is lower than the previous positive_x2\n",
    "            if row['positive_x1'] < prev_positive_x2:\n",
    "                # remove this row from the dataframe\n",
    "                param_vel_positive_final = param_vel_positive_final.drop(i)\n",
    "            else:\n",
    "                # update prev_positive_x2 if positive_x1 is greater than or equal to prev_positive_x2\n",
    "                prev_positive_x2 = row['positive_x2']\n",
    "        else:\n",
    "            # initialize prev_positive_x2 with the first row value\n",
    "            prev_positive_x2 = row['positive_x2']\n",
    "\n",
    "\n",
    "    # Velocity for positive pieak calculation\n",
    "    # Calculate the difference between y2 and y1 divided by the difference between x2 and x1\n",
    "    param_vel_positive_final['slope'] = (param_vel_positive_final['positive_y2'] - param_vel_positive_final['positive_y1']) / (param_vel_positive_final['positive_x2'] - param_vel_positive_final['positive_x1'])\n",
    "\n",
    "    # abs\n",
    "    param_vel_positive_final['slope'] = abs(param_vel_positive_final['slope'])\n",
    "\n",
    "    # Reindexing\n",
    "    param_vel_positive_final = param_vel_positive_final.reset_index(drop=True)\n",
    "\n",
    "    # Remove unwant values\n",
    "    #param_gain_positive_final.loc[param_gain_positive_final['slope'] > 1.09, 'slope'] = np.nan  \n",
    "\n",
    "    # Calculate the average slope\n",
    "    average_positive_slope = abs(param_vel_positive_final['slope'].mean())\n",
    "\n",
    "    # Print the average slope\n",
    "    #print(average_positive_slope)\n",
    "\n",
    "\n",
    "    # Negative time start trimming\n",
    "    # Select the non-empty values in the 'Pos_Start' column\n",
    "    neg_start_values = df_test.loc[df_test['NegTim_Start'] != '', 'NegTim_Start'].values\n",
    "\n",
    "    # Round the values in the 'Pos_Start' column to two decimal places\n",
    "    rounded_neg_start_values = []\n",
    "    for value in neg_start_values:\n",
    "        rounded_neg_start_values.append(round(value - 0.003, 2))\n",
    "\n",
    "    # Convert the list of rounded values back to a NumPy array\n",
    "    negtim_start_values = np.array(rounded_neg_start_values)\n",
    "\n",
    "    # Print the non-empty values\n",
    "    #print(negtim_start_values)\n",
    "\n",
    "\n",
    "    # Negative Time End Triming\n",
    "    # Select the non-empty values in the 'Pos_Start' column\n",
    "    neg_end_values = df_test.loc[df_test['NegTim_End'] != '', 'NegTim_End'].values\n",
    "\n",
    "    # Round the values in the 'Pos_Start' column to two decimal places\n",
    "    # rounded_neg_end_values = []\n",
    "    # for value in neg_end_values:\n",
    "    #     rounded_neg_end_values.append(round(value - 0.02, 2))\n",
    "\n",
    "    # Convert the list of rounded values back to a NumPy array\n",
    "    negtim_end_values = np.array(neg_end_values)\n",
    "\n",
    "\n",
    "    # Map the start negative time to POS in raw data\n",
    "    # Create a dictionary from the mapping list\n",
    "    mapping_list = negtim_start_values\n",
    "\n",
    "    # Map the values to the 'POS' column in raw\n",
    "    mapped_negSt = data.loc[data['Position'].isin(mapping_list),'Time']\n",
    "\n",
    "\n",
    "\n",
    "    # Ma the end of negative time to pos in raw data\n",
    "    # Create a dictionary from the mapping list\n",
    "    mapping_list = negtim_end_values\n",
    "\n",
    "    # Map the values to the 'POS' column in raw\n",
    "    mapped_negEnd = data.loc[data['Position'].isin(mapping_list),'Time']\n",
    "\n",
    "\n",
    "    # Velocity param negative datafrmae\n",
    "    # column miss match\n",
    "    # Check lengths and truncate longer column \n",
    "    if len(negtim_start_values) > len(mapped_negSt): \n",
    "        negtim_start_values = negtim_start_values[:len(mapped_negSt)] \n",
    "    elif len(mapped_negSt) > len(negtim_start_values):\n",
    "        mapped_negSt = mapped_negSt[:len(negtim_start_values)]  \n",
    "\n",
    "\n",
    "    data_param = {'negative_x1':negtim_start_values,'negative_y1':mapped_negSt}             \n",
    "    param_vel_start = pd.DataFrame(data_param)\n",
    "    data_param= {'negative_x2':negtim_end_values,'negative_y2':mapped_negEnd}\n",
    "    param_vel_end = pd.DataFrame(data_param)\n",
    "\n",
    "    # Reset the indices of the DataFrames\n",
    "    param_vel_start = param_vel_start.reset_index(drop=True)\n",
    "    param_vel_end = param_vel_end.reset_index(drop=True)\n",
    "\n",
    "    # Concatenate the DataFrames horizontally\n",
    "    param_vel_negative_final = pd.concat([param_vel_start,param_vel_end],axis=1)\n",
    "    param_vel_negative_final['Del_X'] = param_vel_negative_final['negative_x2'] - param_vel_negative_final['negative_x1']\n",
    "    #param_vel_negative_final = param_vel_negative_final.fillna(method='ffill')\n",
    "    #param_vel_negative_final\n",
    "\n",
    "    # Remove short duration\n",
    "    # param_vel_negative_final = param_vel_negative_final[(param_vel_negative_final['Del_X'] > 0.3) & \n",
    "    #                                                     (param_vel_negative_final['Del_X'] < 2.07)]\n",
    "    param_vel_negative_final = param_vel_negative_final[param_vel_negative_final['Del_X'] < 2.07]\n",
    "    #                                                     \n",
    "    param_vel_negative_final['Del_X'] = (param_vel_negative_final['negative_x2'] - \n",
    "                                        param_vel_negative_final['negative_x1']).where(~param_vel_negative_final['negative_x2'].isnull(), np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # # Remove short duration SWJ from 50 ms to 400 ms\n",
    "    param_vel_negative_final = param_vel_negative_final[(param_vel_negative_final['Del_X'] > 0.4) & \n",
    "                                                        (param_vel_negative_final['Del_X'] < 2.00)]\n",
    "\n",
    "\n",
    "    # iterate over the rows of the dataframe\n",
    "    prev_negative_x2 = None\n",
    "    for i, row in param_vel_negative_final.iterrows():\n",
    "        # check if this is not the first row\n",
    "        if prev_negative_x2 is not None:\n",
    "            # check if positive_x1 is lower than the previous positive_x2\n",
    "            if row['negative_x1'] < prev_negative_x2:\n",
    "                # remove this row from the dataframe\n",
    "                param_vel_negative_final = param_vel_negative_final.drop(i)\n",
    "            else:\n",
    "                # update prev_positive_x2 if positive_x1 is greater than or equal to prev_positive_x2\n",
    "                prev_megatove_x2 = row['negative_x2']\n",
    "        else:\n",
    "            # initialize prev_positive_x2 with the first row value\n",
    "            prev_negative_x2 = row['negative_x2']\n",
    "\n",
    "    # Velocity for Negative peak calculation\n",
    "    # Calculate the difference between y2 and y1 divided by the difference between x2 and x1\n",
    "    param_vel_negative_final['slope'] = (param_vel_negative_final['negative_y2']\n",
    "                                        - param_vel_negative_final['negative_y1']) / (param_vel_negative_final['negative_x2'] \n",
    "                                        - param_vel_negative_final['negative_x1'])\n",
    "\n",
    "    # abs\n",
    "    param_vel_negative_final['slope'] = abs(param_vel_negative_final['slope'])\n",
    "\n",
    "    param_vel_negative_final['slope'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Reindexing\n",
    "    param_vel_negative_final = param_vel_negative_final.reset_index(drop=True)\n",
    "\n",
    "    # Remove unwant values\n",
    "    #param_gain_negative_final.loc[(param_gain_negative_final['slope'] < 0.80) |  \n",
    "    #                              (param_gain_negative_final['slope'] > 1.09), \n",
    "    #                              'slope'] = np.nan\n",
    "    # Calculate the average slope\n",
    "    average_negative_slope = abs(param_vel_negative_final['slope'].mean())\n",
    "\n",
    "    # Print the average slope\n",
    "    #print(average_negative_slope)\n",
    "\n",
    "\n",
    "    # Total velocity for both positive and negative\n",
    "    Final_Vel = pd.concat([param_vel_positive_final[['Del_X','slope']],\n",
    "                        param_vel_negative_final[['Del_X','slope']]], axis=0, join='outer')\n",
    "\n",
    "    # Counter chck with duration and velocity\n",
    "    Final_Vel['Checked_velocity'] = Final_Vel['slope'] * Final_Vel['Del_X']\n",
    "    try:\n",
    "        Vel = Final_Vel['Checked_velocity'].sum()/Final_Vel['Del_X'].sum()\n",
    "    except Exception as e:\n",
    "            print(f\"Error processing file {subject_code}: {e}\")\n",
    "    # Calculate gain\n",
    "    speed = 4 # stimulus speed\n",
    "    total_gain = Vel/speed\n",
    "    #print(\"The gain for this subject is:\",total_gain)\n",
    "    result = {\"SubjectID\":subject_code ,\"gain\":total_gain}\n",
    "    FirstTrialHC.append(result)\n",
    "    print('File '+ str(subject_code)+ ' is done.') \n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "FirstTrialHC_df = pd.DataFrame(FirstTrialHC)\n",
    "FirstTrialHC_df.to_csv('FourSecondTrialPD.csv',index=False)\n",
    "#print(FirstTrialHC_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC\n",
    "\n",
    "# Read the CSV files\n",
    "FirstTrialHC = pd.read_csv('FourFirstTrialHC.csv')\n",
    "\n",
    "# Rename the 'Gain' column in the first DataFrame to avoid confusion\n",
    "FirstTrialHC = FirstTrialHC.rename(columns={'gain': 'gain1'})\n",
    "\n",
    "SecondTrialHC = pd.read_csv('FourSecondTrialHC.csv')\n",
    "SecondTrialHC = SecondTrialHC.rename(columns={'gain': 'gain2'})\n",
    "\n",
    "# Combine the DataFrames side by side\n",
    "Total_HC = pd.concat([FirstTrialHC.set_index('SubjectID'), SecondTrialHC.set_index('SubjectID')], axis=1)\n",
    "\n",
    "# Calculate the average gain for each row, ignoring NaN values\n",
    "Total_HC['AutoGain'] = Total_HC[['gain1', 'gain2']].apply(lambda x: np.nanmean(x), axis=1)\n",
    "\n",
    "# Reset the index and save the combined DataFrame to a new CSV file\n",
    "Total_HC.reset_index().to_csv('FourHCAverageGain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC\n",
    "\n",
    "# Read the CSV files\n",
    "FirstTrialPD = pd.read_csv('FourFirstTrialPD.csv')\n",
    "\n",
    "# Rename the 'Gain' column in the first DataFrame to avoid confusion\n",
    "FirstTrialPD = FirstTrialPD.rename(columns={'gain': 'gain1'})\n",
    "\n",
    "SecondTrialPD = pd.read_csv('FourSecondTrialPD.csv')\n",
    "SecondTrialPD = SecondTrialPD.rename(columns={'gain': 'gain2'})\n",
    "\n",
    "# Combine the DataFrames side by side\n",
    "Total_PD = pd.concat([FirstTrialPD.set_index('SubjectID'), SecondTrialPD.set_index('SubjectID')], axis=1)\n",
    "\n",
    "# Calculate the average gain for each row, ignoring NaN values\n",
    "Total_PD['AutoGain'] = Total_PD[['gain1', 'gain2']].apply(lambda x: np.nanmean(x), axis=1)\n",
    "\n",
    "# Reset the index and save the combined DataFrame to a new CSV file\n",
    "Total_PD.reset_index().to_csv('FourPDAverageGain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the DataFrames\n",
    "FourHCPD = pd.concat([Total_HC, Total_PD], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_ID = FourHCPD.index\n",
    "manual_values = [ 0.842657429,\n",
    "0.927453825,\n",
    "0.860997989,\n",
    "0.82628446,\n",
    "0.907866303,\n",
    "0.886319853,\n",
    "0.879363614,\n",
    "0.945246227,\n",
    "0.865730996,\n",
    "0.949044696,\n",
    "0.927054434,\n",
    "0.907460104,\n",
    "0.768451296,\n",
    "0.824017605,\n",
    "0.811562703,\n",
    "0.864465361,\n",
    "1.018469625,\n",
    "0.835846561,\n",
    "\n",
    "0.701047864,\n",
    "0.889725099,\n",
    "0.860892919,\n",
    "0.842337432,\n",
    "0.603231184,\n",
    "1.11633862,\n",
    "0.837634157,\n",
    "0.872113846,\n",
    "1.006655281,\n",
    "0.867235325,\n",
    "0.864534497,\n",
    "0.911235509,\n",
    "0.863969644,\n",
    "0.810695263,\n",
    "0.871698328,\n",
    "0.665919935,\n",
    "0.531701684,\n",
    "0.804825843,\n",
    "0.849537458,\n",
    "0.843883704,\n",
    "0.69678833,\n",
    "0.783769251,\n",
    "0.87821069,\n",
    "0.712485419,\n",
    "0.82906287,\n",
    "0.792533492,\n",
    "0.96919708,\n",
    "0.564497325,\n",
    "0.566934463,\n",
    "0.745104906,\n",
    "0.955859208,\n",
    "]\n",
    "manual_gain = pd.DataFrame({'SubjectID':manual_ID, \"ManualGain\":manual_values})\n",
    "manual_gain.set_index('SubjectID', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AutoGain  ManualGain  Difference\n",
      "SubjectID                                  \n",
      "PD001      0.867752    0.842657    0.025094\n",
      "PD002      0.951287    0.927454    0.023833\n",
      "PD003      0.817715    0.860998   -0.043283\n",
      "PD004      0.817567    0.826284   -0.008717\n",
      "PD005      0.890504    0.907866   -0.017362\n",
      "PD006      0.895419    0.886320    0.009099\n",
      "PD007      0.934830    0.879364    0.055467\n",
      "PD008      0.800924    0.945246   -0.144322\n",
      "PD009      0.902743    0.865731    0.037012\n",
      "PD010      0.992952    0.949045    0.043907\n",
      "PD011      0.946505    0.927054    0.019450\n",
      "PD012      0.875945    0.907460   -0.031515\n",
      "PD013      0.888113    0.768451    0.119662\n",
      "PDN015     0.796665    0.824018   -0.027353\n",
      "PDN017     0.999125    0.811563    0.187562\n",
      "PDN018     0.968398    0.864465    0.103933\n",
      "PDN019     0.992356    1.018470   -0.026113\n",
      "PD026      0.837941    0.835847    0.002095\n",
      "PD104      0.916583    0.701048    0.215535\n",
      "PD106      0.846278    0.889725   -0.043448\n",
      "PD107      0.873313    0.860893    0.012420\n",
      "PD108      0.886549    0.842337    0.044211\n",
      "PD109      0.792564    0.603231    0.189333\n",
      "PD111      0.658984    1.116339   -0.457354\n",
      "PD112      0.966028    0.837634    0.128394\n",
      "PD119      0.770009    0.872114   -0.102105\n",
      "PD120      0.921913    1.006655   -0.084742\n",
      "PD121      0.991678    0.867235    0.124443\n",
      "PD122      0.682876    0.864534   -0.181658\n",
      "PD126      0.977870    0.911236    0.066635\n",
      "PDPY101    0.958584    0.863970    0.094614\n",
      "PDQE102    0.825615    0.810695    0.014920\n",
      "PDQE103    0.930055    0.871698    0.058356\n",
      "PDQE104    0.921177    0.665920    0.255257\n",
      "PDQE105    0.806780    0.531702    0.275078\n",
      "PDQE107    0.844825    0.804826    0.039999\n",
      "PDQE108    0.973933    0.849537    0.124396\n",
      "PDQE112    0.873219    0.843884    0.029335\n",
      "PDQE113    0.991239    0.696788    0.294451\n",
      "PDQE114    0.742903    0.783769   -0.040866\n",
      "PDQE115    0.836949    0.878211   -0.041262\n",
      "PDPW104    0.750849    0.712485    0.038364\n",
      "PDPW106    0.866056    0.829063    0.036993\n",
      "PDPW107    0.935671    0.792533    0.143137\n",
      "PDPW109    0.814121    0.969197   -0.155076\n",
      "PDPW110    0.859974    0.564497    0.295477\n",
      "PDPW111    0.939675    0.566934    0.372741\n",
      "PDPW112    0.891143    0.745105    0.146038\n",
      "PDPW113    0.998365    0.955859    0.042505\n",
      "The mean difference 0.04621566681599515\n"
     ]
    }
   ],
   "source": [
    "ComFourHCPD = pd.concat([FourHCPD, manual_gain], axis=1)\n",
    "ComFourHCPD = ComFourHCPD.drop(['gain1','gain2'],axis=1)\n",
    "\n",
    "ComFourHCPD['Difference'] = ComFourHCPD['AutoGain'] - ComFourHCPD['ManualGain']\n",
    "ComFourHCPD.to_csv('ComFourHCPD.csv')\n",
    "print(ComFourHCPD)\n",
    "\n",
    "print(\"The mean difference\",ComFourHCPD['Difference'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_coef = ComFourHCPD['ManualGain'].corr(ComFourHCPD['AutoGain'])\n",
    "# Create scatter plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plot = sns.scatterplot(x='ManualGain', y='AutoGain', data=ComFourHCPD)\n",
    "plot.set_title(f'Correlation (r): {correlation_coef:.2f}')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
