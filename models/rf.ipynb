{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tuesday 3 April 2022\n",
    "Author: ZMW\n",
    "\"\"\"\n",
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn import *\n",
    "import pickle\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from xgboost import plot_importance\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import shap\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "path = os.getcwd()\n",
    "dirname = os.path.dirname(path)\n",
    "#for windown\n",
    "#data_file = \"data\\\\data.csv\"\n",
    "#for linux\n",
    "data_file = 'data/data.csv'\n",
    "data_path = os.path.join(dirname,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the fitted dataset\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add gain as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneDegGain = np.array([\n",
    "                    0.912073221615219,\n",
    "                    0.913615300167855,\n",
    "                    0.946453363089275,\n",
    "                    0.930324124079886,\n",
    "                    1.02416020436668,\n",
    "                    0.860239837548296,\n",
    "                    0.964705222165739,\n",
    "                    0.926124390992111,\n",
    "                    0.968894500894799,\n",
    "                    0.971483673217362,\n",
    "                    0.944374366569671,\n",
    "                    0.933778991410942,\n",
    "                    0.890761283462127,\n",
    "\n",
    "                    1.01702677636733,\n",
    "                    1.01132254481336,\n",
    "                    0.860332024178068,\n",
    "                    0.898244125409108,\n",
    "                    0.79226520992959,\n",
    "                    0.86763213956782,\n",
    "\n",
    "                    1.04294995675946,\n",
    "                    0.954852019394754,\n",
    "                    0.83139435252038,\n",
    "                    0.969027023632338,\n",
    "                    0.819025317130086,\n",
    "                    1.59441787272771,\n",
    "                    0.827558754578517,\n",
    "                    0.882328237761475,\n",
    "                    0.888806663106777  \n",
    "                ])\n",
    "\n",
    "TowDegGain  = np.array([\n",
    "                    0.88795482315922,\n",
    "                    0.85125583179904,\n",
    "                    0.90557113971074,\n",
    "                    0.839308531914961,\n",
    "                    0.944624517823793,\n",
    "                    0.936063494064383,\n",
    "                    0.919761689613053,\n",
    "                    0.857703024614198,\n",
    "                    0.973218178159532,\n",
    "                    0.936570806828469,\n",
    "                    0.955653090017782,\n",
    "                    0.943385867113339,\n",
    "                    1.0186446733178,\n",
    "\n",
    "                    0.957719524164782,\n",
    "                    0.847863270306327,\n",
    "                    0.762131387734656,\n",
    "                    0.71762368625312,\n",
    "                    0.699023420441996,\n",
    "                    0.860669705999712,\n",
    "                    \n",
    "                    0.882514198813699,\n",
    "                    0.900439093391636,\n",
    "                    0.852845556682743,\n",
    "                    0.662387043701962,\n",
    "                    1.02691189892667,\n",
    "                    0.929980500477329,\n",
    "                    0.795054974778894,\n",
    "                    0.915409616170048,\n",
    "                    0.936562782215738\n",
    "])\n",
    "\n",
    "FourDegGain = np.array([\n",
    "                    0.842657428787201,\n",
    "                    0.927453824629543,\n",
    "                    0.86099798858682,\n",
    "                    0.826284460023473,\n",
    "                    0.907866303422781,\n",
    "                    0.886319852935139,\n",
    "                    0.879363613650586,\n",
    "                    0.945246226705543,\n",
    "                    0.865730996104868,\n",
    "                    0.949044695789533,\n",
    "                    0.927054434038832,\n",
    "                    0.907460103985577,\n",
    "                    0.768451296309936,\n",
    "\n",
    "                    0.670432552659765,\n",
    "                    0.82906287014668,\n",
    "                    0.792533491957787,\n",
    "                    0.564497325152498,\n",
    "                    0.566934462769341,\n",
    "                    0.745104906289544,\n",
    "\n",
    "                    0.863969643770036,\n",
    "                    0.810695262798471,\n",
    "                    0.665919934919724,\n",
    "                    0.531701684005337,\n",
    "                    0.804825842988611,\n",
    "                    0.849537457619557,\n",
    "                    0.843883703581647,\n",
    "                    0.696788329556185,\n",
    "                    0.878210689819177\n",
    "])\n",
    "\n",
    "SixDegGain = np.array([\n",
    "                    0.795081992082097,\n",
    "                    0.810824945533769,\n",
    "                    0.776092810922058,\n",
    "                    0.667632972614243,\n",
    "                    0.875563679555973,\n",
    "                    0.832291613200056,\n",
    "                    0.896167465701247,\n",
    "                    0.838934215329476,\n",
    "                    0.91951999621913,\n",
    "                    0.931875303042642,\n",
    "                    0.881653294348028,\n",
    "                    0.866711106710116,\n",
    "                    0.950478365248271,\n",
    "\n",
    "                    0.876172814217401,\n",
    "                    0.793820437144166,\n",
    "                    0.674619968989113,\n",
    "                    0.508275303789709,\n",
    "                    0.454613572040806,\n",
    "                    0.761053355757645,\n",
    "\n",
    "                    0.708138512300574,\n",
    "                    0.875686044405767,\n",
    "                    0.62197374329538,\n",
    "                    0.682965128345167,\n",
    "                    0.745383783235028,\n",
    "                    0.904919560234923,\n",
    "                    0.97349927736433,\n",
    "                    0.790221320229067,\n",
    "                    0.96896278814672\n",
    "])\n",
    "\n",
    "EightDegGain = np.array([\n",
    "                    0.738482610210994,\n",
    "                    0.986636423035039,\n",
    "                    0.745501747649165,\n",
    "                    0.757990700258398,\n",
    "                    0.909797906001487,\n",
    "                    0.781053010159343,\n",
    "                    0.85865978762173,\n",
    "                    0.859516710190982,\n",
    "                    0.885411917285177,\n",
    "                    0.828367438419201,\n",
    "                    0.911980104842521,\n",
    "                    0.863014297113752,\n",
    "                    0.708399551278433,\n",
    "\n",
    "                    0.673980441334396,\n",
    "                    0.795542507563886,\n",
    "                    0.795542507563886,\n",
    "                    0.570216915379213,\n",
    "                    0.470689666436208,\n",
    "                    0.816745486005565,\n",
    "\n",
    "                    0.730673411270229,\n",
    "                    0.84023883503095,\n",
    "                    0.634293750883143,\n",
    "                    0.529398709071705,\n",
    "                    0.750469831451345,\n",
    "                    0.748589580457503,\n",
    "                    0.881237281923916,\n",
    "                    0.750773552799239,\n",
    "                    0.972603229161408\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to dataframe\n",
    "gain = pd.DataFrame({'OneDegGain':OneDegGain,'TowDegGain':TowDegGain,'FourDegGain':FourDegGain,\n",
    "                    'SixDegGain':SixDegGain,'EightDegGain':EightDegGain})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat with main dataframe\n",
    "gain_df = pd.concat([data, gain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gain\n",
    "# Standardization\n",
    "sc = StandardScaler()\n",
    "data_input = pd.DataFrame(sc.fit_transform(gain_df.iloc[:,2:]),index=gain_df.iloc[:,2:].index, columns= gain_df.iloc[:,2:].columns)\n",
    "\n",
    "# Features and labels\n",
    "x = data_input.iloc[:,2:]\n",
    "y = gain_df.iloc[:,0]\n",
    "\n",
    "## Convert the categorical variables to number\n",
    "LabelEncoder_gender = LabelEncoder()\n",
    "y = LabelEncoder_gender.fit_transform(y)\n",
    "\n",
    "# convert array to series \n",
    "y = pd.Series(y,name='Label')\n",
    "df = pd.concat([x,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Without gain\n",
    "# # Standardization\n",
    "# sc = StandardScaler()\n",
    "# data_input = pd.DataFrame(sc.fit_transform(data.iloc[:,2:]),index=data.iloc[:,2:].index, columns= data.iloc[:,2:].columns)\n",
    "\n",
    "# # Features and labels\n",
    "# x = data_input.iloc[:,2:]\n",
    "# y = data.iloc[:,0]\n",
    "\n",
    "# ## Convert the categorical variables to number\n",
    "# LabelEncoder_gender = LabelEncoder()\n",
    "# y = LabelEncoder_gender.fit_transform(y)\n",
    "\n",
    "# # convert array to series \n",
    "# y = pd.Series(y,name='Label')\n",
    "# df = pd.concat([x,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting feature\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Without gain\n",
    "# # StratifiedKFold\n",
    "# # create stratifiedKFold object\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# rf_accu_stratified = []\n",
    "\n",
    "# # Feature Scaling for input features\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# # create classifier objects\n",
    "# model = RandomForestClassifier()\n",
    "# for train_index, test_index in skf.split(x,y):\n",
    "#     x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "#     y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "#     model.fit(x_train_fold, y_train_fold)\n",
    "#     rf_accu_stratified.append(model.score(x_test_fold, y_test_fold))\n",
    "\n",
    "# print('RF based model accuracy score: {0:0.4f}'.format(mean(rf_accu_stratified)),'+/-',std(rf_accu_stratified))\n",
    "\n",
    "# #print(\"RF based model accuracy score: {0:0.4f}\".format(all_run_df['acc'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With gain\n",
    "# StratifiedKFold\n",
    "# create stratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "rf_accu_stratified = []\n",
    "\n",
    "# Feature Scaling for input features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# create classifier objects\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    model.fit(x_train_fold, y_train_fold)\n",
    "    rf_accu_stratified.append(model.score(x_test_fold, y_test_fold))\n",
    "\n",
    "print('RF based model accuracy score: {0:0.4f}'.format(mean(rf_accu_stratified)),'+/-',std(rf_accu_stratified))\n",
    "\n",
    "#print(\"RF based model accuracy score: {0:0.4f}\".format(all_run_df['acc'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter list\n",
    "n_estimators_list = [10, 50, 100, 200, 300, 400,500]\n",
    "max_depth_list = range(3, 12)\n",
    "min_samples_leaf_list = [1, 3, 5, 10, 20, 50]\n",
    "max_features_list = ['sqrt', 'log2', 0.7, 0.8, 0.9]\n",
    "min_samples_split_list = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params= {'n_estimators': hp.choice('n_estimators', [10,50,100,300,400,500]),\n",
    "          'max_depth': hp.choice('max_depth', range(3, 12)),\n",
    "          'min_samples_leaf': hp.choice('min_samples_leaf', [1, 3, 5, 10, 20, 50]),\n",
    "          'min_samples_split':hp.choice('min_samples_split',[2,5,10]),\n",
    "          'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0, 0.01),\n",
    "          'max_features': hp.choice('max_features', ['sqrt', 'log2', 0.7, 0.8, 0.9])\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning function\n",
    "def hyperparameter_tuning(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "#   print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = hyperparameter_tuning,\n",
    "                        space = params,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with tuned parameters\n",
    "best_model = RandomForestClassifier(n_estimators=n_estimators_list[best_hyperparams['n_estimators']],\n",
    "                                    max_depth=max_depth_list[best_hyperparams['max_depth']],\n",
    "                                    min_samples_leaf=min_samples_leaf_list[best_hyperparams['min_samples_leaf']],\n",
    "                                    min_samples_split = min_samples_split_list[best_hyperparams['min_samples_split']],\n",
    "                                    max_features=max_features_list[best_hyperparams['max_features']],\n",
    "                                    min_impurity_decrease=best_hyperparams['min_impurity_decrease'],\n",
    "                                    n_jobs=-1, random_state=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "file_name = 'hyper_rf.pkl'\n",
    "pickle.dump(best_model, open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "file_name = 'hyper_rf.pkl'\n",
    "#pickle.dump(best_model, open(file_name,'wb'))\n",
    "\n",
    "#load\n",
    "rf_hyper = pickle.load(open(file_name,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold\n",
    "all_run = []\n",
    "for split in range(30):\n",
    "    #cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=split)\n",
    "    kfold = KFold(n_splits=4, shuffle=True,random_state=split)\n",
    "    scores = cross_val_score(rf_hyper,x,y,scoring='roc_auc', cv=kfold)\n",
    "    result = [[split,scores.mean()]]\n",
    "    all_run += result\n",
    "#print(all_run)\n",
    "all_run_df = pd.DataFrame(all_run,columns=['split','acc'])\n",
    "print(all_run_df['acc'].mean(),all_run_df['acc'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold\n",
    "# create stratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "rf_accu_stratified = []\n",
    "\n",
    "# Feature Scaling for input features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    rf_hyper.fit(x_train_fold, y_train_fold)\n",
    "    rf_accu_stratified.append(rf_hyper.score(x_test_fold, y_test_fold))\n",
    "\n",
    "print('RF model with tuned parameters accuracy score: {0:0.4f}'.format(mean(rf_accu_stratified)))\n",
    "\n",
    "#print(\"RF based model accuracy score: {0:0.4f}\".format(all_run_df['acc'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold\n",
    "data = data[['Label','Patient','C1_8Deg','C2_1Deg','C1_2Deg','C2_6Deg',\n",
    "            'B2_2Deg','B1_6Deg','A1_2Deg','C2_8Deg','A2_8Deg','B1_6Deg']]\n",
    "# data = data[['Label','Patient','B2_6Deg','C2_1Deg','C1_2Deg','C1_8Deg',\n",
    "#             'C2_6Deg','A1_4Deg','A1_6Deg','A1_2Deg','B2_2Deg','B1_6Deg']]\n",
    "\n",
    "# data = data[['Label','Patient','C1_8Deg','C2_1Deg','C2_6Deg','C1_2Deg',\n",
    "#             'B2_2Deg','B2_6Deg','A1_2Deg','B1_6Deg','A1_6Deg','A1_4Deg']]\n",
    "x = data.iloc[:,2:]\n",
    "# sc = StandardScaler()\n",
    "# x = sc.fit_transform(x)\n",
    "y = data.iloc[:,0]\n",
    "y = LabelEncoder_gender.fit_transform(y)\n",
    "# x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "# best_model.fit(x_train, y_train)\n",
    "#best_model.fit(x,y,eval_metric='auc')\n",
    "all_run = []\n",
    "for split in range(30):\n",
    "    #cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=split)\n",
    "    kfold = KFold(n_splits=4, shuffle=True,random_state=split)\n",
    "    scores = cross_val_score(rf_hyper,x,y,scoring='roc_auc', cv=kfold)\n",
    "    result = [[split,scores.mean()]]\n",
    "    all_run += result\n",
    "#print(all_run)\n",
    "all_run_df = pd.DataFrame(all_run,columns=['split','acc'])\n",
    "print(all_run_df['acc'].mean(),all_run_df['acc'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratisfied with feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Label','Patient','C1_8Deg','C2_1Deg','C1_2Deg','C2_6Deg',\n",
    "            'B2_2Deg','B1_6Deg','A1_2Deg','C2_8Deg','A2_8Deg','B1_6Deg']]\n",
    "x = data.iloc[:,2:]\n",
    "# sc = StandardScaler()\n",
    "# x = sc.fit_transform(x)\n",
    "y = data.iloc[:,0]\n",
    "y = LabelEncoder_gender.fit_transform(y)\n",
    "# spliting feature\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "# Hyperparameter Tuning function\n",
    "def hyperparameter_tuning(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "#   print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = hyperparameter_tuning,\n",
    "                        space = params,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with tuned parameters\n",
    "best_model = RandomForestClassifier(n_estimators=n_estimators_list[best_hyperparams['n_estimators']],\n",
    "                                    max_depth=max_depth_list[best_hyperparams['max_depth']],\n",
    "                                    min_samples_leaf=min_samples_leaf_list[best_hyperparams['min_samples_leaf']],\n",
    "                                    min_samples_split = min_samples_split_list[best_hyperparams['min_samples_split']],\n",
    "                                    max_features=max_features_list[best_hyperparams['max_features']],\n",
    "                                    min_impurity_decrease=best_hyperparams['min_impurity_decrease'],\n",
    "                                    n_jobs=-1, random_state=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Stratified latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'hyper_stra_rf.pkl'\n",
    "pickle.dump(best_model, open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "file_name = 'hyper_stra_rf.pkl'\n",
    "#pickle.dump(best_model, open(file_name,'wb'))\n",
    "\n",
    "#load\n",
    "rf_hyper = pickle.load(open(file_name,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits= 10, shuffle=True, random_state=1)\n",
    "rf_accu_stratified = []\n",
    "\n",
    "# Feature Scaling for input features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    rf_hyper.fit(x_train_fold, y_train_fold)\n",
    "    rf_accu_stratified.append(rf_hyper.score(x_test_fold, y_test_fold))\n",
    "\n",
    "print('RF model with feature importance accuracy score: {0:0.4f}'.format(mean(rf_accu_stratified)), std(rf_accu_stratified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyper.fit(x_train, y_train)\n",
    "y_pred = rf_hyper.predict_proba(x_test)[:,1]\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# Accuracy\n",
    "accuracy = roc_auc_score(y_test,predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion = confusion_matrix(y_test,predictions)\n",
    "print(confusion)\n",
    "\n",
    "#  Sensitivity \n",
    "TP = confusion[1,1] # true positives\n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # False positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "sensitivity = TP/float(TP+FN)\n",
    "print(sensitivity)\n",
    "\n",
    "# Specificity\n",
    "specificity = TN/float(TN+FP)\n",
    "print(specificity)\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test,predictions)\n",
    "fpr , tpr , thresholds = roc_curve (y_test, predictions)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Parkinson','Non Parkinson']\n",
    "disp = plot_confusion_matrix(rf_hyper, x_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "\n",
    "#plt.savefig('cm.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sensitivity \n",
    "TP = confusion[1,1] # true positives\n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # False positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "sensitivity = TP/float(TP+FN)\n",
    "print(sensitivity)\n",
    "\n",
    "# Specificity\n",
    "specificity = TN/float(TN+FP)\n",
    "print(specificity)\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "fpr , tpr , thresholds = roc_curve (y_test, y_pred)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr,tpr): \n",
    "  random_probs = [0 for i in range(len(y_test))]\n",
    "  p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "  plt.plot(fpr,tpr,label='ROC(area=0.90')\n",
    "  plt.plot(p_fpr, p_tpr,'--',color='red') \n",
    "  plt.axis([-0.05,1.05,-0.05,1.05]) \n",
    "  plt.title('ROC curve')\n",
    "  plt.xlabel('False Positive Rate') \n",
    "  plt.ylabel('True Positive Rate') \n",
    "  plt.legend()\n",
    "  #plt.savefig('roc_curve.png',dpi=300)\n",
    "  plt.show()    \n",
    "  \n",
    "plot_roc_curve (fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(x_train,y_train)\n",
    "# print the JS visualization code to the notebook\n",
    "\n",
    "shap.initjs()\n",
    "X_importance = x_test\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(X_importance)\n",
    "shap.summary_plot(shap_values, X_importance,max_display=10,class_names=['Non_Parkinson','Parkinson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37e48532695005f6b8be481dca9311b0406960c07b920c9bcff5b3361c45626c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
