{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tuesday 3 April 2022\n",
    "Author: ZMW\n",
    "\"\"\"\n",
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from xgboost import plot_importance\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the fitted dataset\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Patient</th>\n",
       "      <th>A1_1Deg</th>\n",
       "      <th>A1_1Deg_err</th>\n",
       "      <th>B1_1Deg</th>\n",
       "      <th>B1_1Deg_err</th>\n",
       "      <th>C1_1Deg</th>\n",
       "      <th>C1_1Deg_err</th>\n",
       "      <th>1_Deg_ResSoS_1</th>\n",
       "      <th>1Deg_AdjR2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>8_Deg_ResSoS_1</th>\n",
       "      <th>8Deg_AdjR2_1</th>\n",
       "      <th>A2_8Deg</th>\n",
       "      <th>A2_8Deg_err</th>\n",
       "      <th>B2_8Deg</th>\n",
       "      <th>B2_8Deg_err</th>\n",
       "      <th>C2_8Deg</th>\n",
       "      <th>C2_8Deg_err</th>\n",
       "      <th>8_Deg_ResSoS_2</th>\n",
       "      <th>8Deg_AdjR2_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not_Parkinson's</td>\n",
       "      <td>PD001</td>\n",
       "      <td>10.388190</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.049329</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>8928.709194</td>\n",
       "      <td>0.990598</td>\n",
       "      <td>...</td>\n",
       "      <td>6698.838281</td>\n",
       "      <td>0.951413</td>\n",
       "      <td>10.273124</td>\n",
       "      <td>0.044206</td>\n",
       "      <td>0.386347</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>6809.455800</td>\n",
       "      <td>0.939095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not_Parkinson's</td>\n",
       "      <td>PD002</td>\n",
       "      <td>10.429055</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>11388.604704</td>\n",
       "      <td>0.988092</td>\n",
       "      <td>...</td>\n",
       "      <td>4769.901822</td>\n",
       "      <td>0.967360</td>\n",
       "      <td>11.482500</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.395412</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>8383.481840</td>\n",
       "      <td>0.939586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not_Parkinson's</td>\n",
       "      <td>PD003</td>\n",
       "      <td>10.097088</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.049368</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>6140.292312</td>\n",
       "      <td>0.993141</td>\n",
       "      <td>...</td>\n",
       "      <td>3488.747176</td>\n",
       "      <td>0.968709</td>\n",
       "      <td>10.084338</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.394595</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.035466</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>1349.962240</td>\n",
       "      <td>0.987259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not_Parkinson's</td>\n",
       "      <td>PD004</td>\n",
       "      <td>10.482881</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>117748.979710</td>\n",
       "      <td>0.879372</td>\n",
       "      <td>...</td>\n",
       "      <td>10972.045844</td>\n",
       "      <td>0.920137</td>\n",
       "      <td>11.493414</td>\n",
       "      <td>0.048867</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>8242.136178</td>\n",
       "      <td>0.940370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not_Parkinson's</td>\n",
       "      <td>PD005</td>\n",
       "      <td>10.181273</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.049368</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>18447.340517</td>\n",
       "      <td>0.979692</td>\n",
       "      <td>...</td>\n",
       "      <td>18268.960666</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>10.370348</td>\n",
       "      <td>0.036121</td>\n",
       "      <td>0.395392</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>4485.300264</td>\n",
       "      <td>0.960035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label Patient    A1_1Deg  A1_1Deg_err   B1_1Deg  B1_1Deg_err  \\\n",
       "0  Not_Parkinson's   PD001  10.388190     0.006132  0.049329     0.000006   \n",
       "1  Not_Parkinson's   PD002  10.429055     0.006929  0.049478     0.000007   \n",
       "2  Not_Parkinson's   PD003  10.097088     0.005091  0.049368     0.000006   \n",
       "3  Not_Parkinson's   PD004  10.482881     0.022179  0.049585     0.000023   \n",
       "4  Not_Parkinson's   PD005  10.181273     0.008833  0.049368     0.000010   \n",
       "\n",
       "    C1_1Deg  C1_1Deg_err  1_Deg_ResSoS_1  1Deg_AdjR2_1  ...  8_Deg_ResSoS_1  \\\n",
       "0  0.011989     0.000337     8928.709194      0.990598  ...     6698.838281   \n",
       "1  0.002837     0.000379    11388.604704      0.988092  ...     4769.901822   \n",
       "2  0.005707     0.000287     6140.292312      0.993141  ...     3488.747176   \n",
       "3  0.016056     0.001212   117748.979710      0.879372  ...    10972.045844   \n",
       "4  0.001569     0.000494    18447.340517      0.979692  ...    18268.960666   \n",
       "\n",
       "   8Deg_AdjR2_1    A2_8Deg  A2_8Deg_err   B2_8Deg  B2_8Deg_err   C2_8Deg  \\\n",
       "0      0.951413  10.273124     0.044206  0.386347     0.000384  0.037356   \n",
       "1      0.967360  11.482500     0.049154  0.395412     0.000380 -0.002486   \n",
       "2      0.968709  10.084338     0.019838  0.394595     0.000174 -0.035466   \n",
       "3      0.920137  11.493414     0.048867  0.401386     0.000377 -0.042463   \n",
       "4      0.809586  10.370348     0.036121  0.395392     0.000308 -0.030769   \n",
       "\n",
       "   C2_8Deg_err  8_Deg_ResSoS_2  8Deg_AdjR2_2  \n",
       "0     0.002439     6809.455800      0.939095  \n",
       "1     0.002419     8383.481840      0.939586  \n",
       "2     0.001106     1349.962240      0.987259  \n",
       "3     0.002395     8242.136178      0.940370  \n",
       "4     0.001960     4485.300264      0.960035  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "x = data.iloc[:,2:].values\n",
    "y = data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the categorical variables to number\n",
    "LabelEncoder_gender = LabelEncoder()\n",
    "y = LabelEncoder_gender.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting feature\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter list\n",
    "params = {'C': hp.uniform('C', 0.1, 100), 'gamma': hp.uniform('gamma', 0, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning function\n",
    "def hyperparameter_tuning(params):\n",
    "    clf = svm.SVC(**params, kernel='rbf', random_state=1, probability=True, class_weight='balanced',\n",
    "                        cache_size=2000, max_iter=10000)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "#   print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 145.89trial/s, best loss: -0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "# Optimizing\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = hyperparameter_tuning,\n",
    "                        space = params,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with tuned parameters\n",
    "best_model = svm.SVC(C=best_hyperparams['C'], gamma=best_hyperparams['gamma'], kernel='rbf', random_state=1,\n",
    "                         probability=True, class_weight='balanced', cache_size=2000, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_best_model(arg):\n",
    "    # data set preparation\n",
    "    # data = pd.read_csv('data.csv')\n",
    "    data = arg\n",
    "\n",
    "    ## Convert the categorical variables to number\n",
    "    LabelEncoder_gender = LabelEncoder()\n",
    "    data['Label'] = LabelEncoder_gender.fit_transform(data['Label'])\n",
    "    \n",
    "    # run 50 repetitions\n",
    "    splits = 50\n",
    "    all_set = []\n",
    "    for split in range(1,splits+1):\n",
    "        \n",
    "        seed = split\n",
    "\n",
    "        # data set preparation\n",
    "        train , rest = train_test_split(data,train_size = 0.8,shuffle=True)\n",
    "        validate , test = train_test_split(rest, train_size = 0.5, shuffle=True)\n",
    "\n",
    "        # training set\n",
    "        data_tra_x = train.iloc[:,2:].values\n",
    "        data_tra_y = train.iloc[:,0].values\n",
    "\n",
    "\n",
    "        # validation set\n",
    "        data_val_x = validate.iloc[:,2:].values\n",
    "        data_val_y = validate.iloc[:,0].values\n",
    "\n",
    "\n",
    "        # test set\n",
    "        data_tes_x = test.iloc[:,2:].values\n",
    "        data_tes_y =  test.iloc[:,0].values\n",
    "\n",
    "        best_model = svm.SVC(C=best_hyperparams['C'], gamma=best_hyperparams['gamma'], kernel='rbf', random_state=1,\n",
    "                         probability=True, class_weight='balanced', cache_size=2000, max_iter=10000)\n",
    "    \n",
    "        best_model.fit(data_tra_x,data_tra_y)\n",
    "\n",
    "        # training error\n",
    "        tra_pred = best_model.predict_proba(data_tra_x)\n",
    "        try:\n",
    "            tra_results = [split,'tra',roc_auc_score(data_tra_y,tra_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # validation error\n",
    "        val_pred = best_model.predict_proba(data_val_x)\n",
    "        try:\n",
    "            val_results = [split,'val',roc_auc_score(data_val_y,val_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # testing error\n",
    "        tes_pred = best_model.predict_proba(data_tes_x)\n",
    "        try:\n",
    "            tes_results = [' ','tes',roc_auc_score(data_tes_y,tes_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        all_set += tra_results,val_results,tes_results\n",
    "\n",
    "    all_set_df = pd.DataFrame(all_set,columns=['split','set','acc'])\n",
    "\n",
    "    print('train accuracy',all_set_df[all_set_df['set'] == 'tra']['acc'].mean())\n",
    "    print('validation accuracy',all_set_df[all_set_df['set'] == 'val']['acc'].mean())\n",
    "    print('test accuracy',all_set_df[all_set_df['set'] == 'tes']['acc'].mean())\n",
    "\n",
    "#run_best_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.34\n",
      "validation accuracy 0.455\n",
      "test accuracy 0.435\n"
     ]
    }
   ],
   "source": [
    "run_best_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Label','Patient','C2_6Deg','B2_4Deg','B2_6Deg','C2_4Deg',\n",
    "            'C1_2Deg','C1_8Deg','A1_4Deg_err','C2_1Deg','B1_8Deg','B2_8Deg']]\n",
    "\n",
    "\n",
    "def run_best_model(arg):\n",
    "    # data set preparation\n",
    "    # data = pd.read_csv('data.csv')\n",
    "    data = arg\n",
    "\n",
    "    ## Convert the categorical variables to number\n",
    "    LabelEncoder_gender = LabelEncoder()\n",
    "    data['Label'] = LabelEncoder_gender.fit_transform(data['Label'])\n",
    "    \n",
    "    # run 50 repetitions\n",
    "    splits = 50\n",
    "    all_set = []\n",
    "    for split in range(1,splits+1):\n",
    "        \n",
    "        seed = split\n",
    "\n",
    "        # data set preparation\n",
    "        train , rest = train_test_split(data,train_size = 0.8,shuffle=True)\n",
    "        validate , test = train_test_split(rest, train_size = 0.5, shuffle=True)\n",
    "\n",
    "        # training set\n",
    "        data_tra_x = train.iloc[:,2:].values\n",
    "        data_tra_y = train.iloc[:,0].values\n",
    "\n",
    "\n",
    "        # validation set\n",
    "        data_val_x = validate.iloc[:,2:].values\n",
    "        data_val_y = validate.iloc[:,0].values\n",
    "\n",
    "\n",
    "        # test set\n",
    "        data_tes_x = test.iloc[:,2:].values\n",
    "        data_tes_y =  test.iloc[:,0].values\n",
    "\n",
    "        best_model = svm.SVC(C=best_hyperparams['C'], gamma=best_hyperparams['gamma'], kernel='rbf', random_state=1,\n",
    "                         probability=True, class_weight='balanced', cache_size=2000, max_iter=10000)\n",
    "    \n",
    "        best_model.fit(data_tra_x,data_tra_y)\n",
    "\n",
    "        # training error\n",
    "        tra_pred = best_model.predict_proba(data_tra_x)\n",
    "        try:\n",
    "            tra_results = [split,'tra',roc_auc_score(data_tra_y,tra_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # validation error\n",
    "        val_pred = best_model.predict_proba(data_val_x)\n",
    "        try:\n",
    "            val_results = [split,'val',roc_auc_score(data_val_y,val_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # testing error\n",
    "        tes_pred = best_model.predict_proba(data_tes_x)\n",
    "        try:\n",
    "            tes_results = [' ','tes',roc_auc_score(data_tes_y,tes_pred[:,1])]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        all_set += tra_results,val_results,tes_results\n",
    "\n",
    "    all_set_df = pd.DataFrame(all_set,columns=['split','set','acc'])\n",
    "\n",
    "    print('train accuracy',all_set_df[all_set_df['set'] == 'tra']['acc'].mean())\n",
    "    print('validation accuracy',all_set_df[all_set_df['set'] == 'val']['acc'].mean())\n",
    "    print('test accuracy',all_set_df[all_set_df['set'] == 'tes']['acc'].mean())\n",
    "\n",
    "#run_best_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.19539271839271838\n",
      "validation accuracy 0.25\n",
      "test accuracy 0.18\n"
     ]
    }
   ],
   "source": [
    "run_best_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37e48532695005f6b8be481dca9311b0406960c07b920c9bcff5b3361c45626c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
